import argparse
import csv
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Iterable, List

from camel_tools.morphology.database import MorphologyDB
from camel_tools.morphology.analyzer import Analyzer
from camel_tools.disambig.bert import BERTUnfactoredDisambiguator as Disambig
from transformers import logging as tflogging

from wilddiac_utils import fix_contextual_diacs, remove_contextual_diac_flags
from wilddiac_utils import fix_tanween_alef, fix_diac_order, word_is_oov
from ctpp import ctpp_rerank
from oracle import oracle_rerank_noctx, oracle_rerank_ctx


SCRIPT_PATH = Path(__file__).absolute().parent
S31_DB_PATH = Path(SCRIPT_PATH, 'databases/calima-msa-s31-extended.db')


"""Analysis types that shouldn't be reranked.
"""
IGNORE_SOURCE = frozenset(['foreign', 'digit', 'punc'])


@dataclass(frozen=True)
class ProcessedArgs():
    """Container class to store processed command-line arguments.
    """

    input_path: Path
    output_path: Path
    db_path: Path
    ct_noctx: bool = False
    ct_soloctx: bool = False
    ct_fullctx: bool = False
    ctpp_soloctx: bool = False
    ctpp_fullctx: bool = False
    oracle_noctx: bool = False
    oracle_soloctx: bool = False
    oracle_fullctx: bool = False


@dataclass(frozen=True)
class DataEntry():
    """Container class to store row data from input files.
    """

    sentence_orig: List[str]
    word_index: int
    word: str
    gold_diac: str
    gold_diac_alt: str
    context_before: List[str]
    context_after: List[str]


def create_argparser() -> argparse.ArgumentParser:
    """Create and populate and ArgumentParser instance.
    """

    # TODO: Better description
    parser = argparse.ArgumentParser(
        prog='gen_predictions_single.py',
        description='Generate diacritization predictions from an input file.'
    )

    parser.add_argument(
        '-d', '--db',
        help='path to analyzer database',
        required=True
    )

    parser.add_argument(
        '-o', '--output',
        help='path where output file will be written',
        required=True
    )

    parser.add_argument(
        '--ct-noctx',
        help='generate original CAMeL Tools diacritization with no contextual fixes',
        action='store_true',
        default=False
    )

    parser.add_argument(
        '--ct-soloctx',
        help='generate original CAMeL Tools diacritization using solo context fixes',
        action='store_true',
        default=False
    )

    parser.add_argument(
        '--ct-fullctx',
        help='generate original CAMeL Tools diacritization using full context fixes',
        action='store_true',
        default=False
    )

    parser.add_argument(
        '--ctpp-soloctx',
        help='generate original CT++ diacritization using solo context fixes',
        action='store_true',
        default=False
    )

    parser.add_argument(
        '--ctpp-fullctx',
        help='generate original CT++ diacritization using full context fixes',
        action='store_true',
        default=False
    )

    parser.add_argument(
        '--oracle-noctx',
        help='generate oracle diacritization with no contextual fixes',
        action='store_true',
        default=False
    )

    parser.add_argument(
        '--oracle-soloctx',
        help='generate oracle diacritization using solo context fixes',
        action='store_true',
        default=False
    )

    parser.add_argument(
        '--oracle-fullctx',
        help='generate oracle diacritization using full context fixes',
        action='store_true',
        default=False
    )

    parser.add_argument(
        'INPUT',
        help='the input file to process'
    )

    return parser


def process_args(args: argparse.Namespace) -> ProcessedArgs:
    """Convert parsed args into a ProcessedArgs instance which provides typing
    information and a more consistent naming convention.
    """
    return ProcessedArgs(
        input_path=Path(args.INPUT),
        output_path=Path(args.output),
        db_path=Path(args.db),
        ct_noctx=args.ct_noctx,
        ct_soloctx=args.ct_soloctx,
        ct_fullctx=args.ct_fullctx,
        ctpp_soloctx=args.ctpp_soloctx,
        ctpp_fullctx=args.ctpp_fullctx,
        oracle_noctx=args.oracle_noctx,
        oracle_soloctx=args.oracle_soloctx,
        oracle_fullctx=args.oracle_fullctx
    )


def gen_data_entries(path: Path) -> Iterable[DataEntry]:
    """Iterate over rows in an input TSV file, generating a DataEntry object
    for each.
    """

    with path.open('r', encoding='utf-8') as fp:
        reader = csv.DictReader(fp,
                                dialect='excel-tab',
                                quotechar=None,
                                quoting=csv.QUOTE_NONE)

        for row in reader:
            ctx_before = row['context_before'].strip().split()
            ctx_after = row['context_after'].strip().split()
            word = row['word'].strip()
            gold_diac = row['gold_diac'].strip()
            gold_diac_alt = row.get('gold_diac_alt', '').strip()
            word_index = len(ctx_before)
            sentence_orig = ctx_before + [word] + ctx_after

            yield DataEntry(
                sentence_orig=sentence_orig,
                word_index=word_index,
                word=word,
                gold_diac=gold_diac,
                gold_diac_alt=gold_diac_alt,
                context_before=' '.join(ctx_before),
                context_after=' '.join(ctx_after)
            )


def gen_predictions(args: ProcessedArgs,
                    disambig: Disambig) -> Iterable[dict[str, Any]]:
    """Iterates through all data entries and generates predictions for each.
    See OUTPUT_COLUMNS for a full list of outputs.
    """

    for entry in gen_data_entries(args.input_path):
        sentence = entry.sentence_orig
        word = entry.word
        word_ndx = entry.word_index
        gold_diac = entry.gold_diac
        gold_diac_alt = entry.gold_diac_alt

        pred = {
            'context_before': entry.context_before,
            'word': word,
            'context_after': entry.context_after,
            'gold_diac': gold_diac,
            'gold_diac_alt': gold_diac_alt,
        }

        # Generate analyses using CAMeL Tools' original ranking
        sent_disambig = disambig.disambiguate(sentence)
        sent_diacs = [w.analyses[0].diac for w in sent_disambig]
        word_analyses = sent_disambig[word_ndx].analyses

        # If no analyses exist for a word use the word itself for all
        # predictions and mark it as out-of-vocabulary.
        # This shouldn't happen when analyzer is set to generate backoff
        # analyses.
        if len(word_analyses) == 0:
            word_diac = word_analyses[0].diac
            pred['is_oov'] = True
            pred['ct_diac_noctx'] = word
            pred['ct_diac_soloctx'] = word
            pred['ct_diac_fullctx'] = word
            pred['ctpp_diac_soloctx'] = word
            pred['ctpp_diac_fullctx'] = word
            pred['oracle_diac_soloctx'] = word
            pred['oracle_diac_fullctx'] = word
            yield pred
            continue

        # If word is a digit, punctuation, or foreign use the word itself for
        # all predictions as it would be the only analysis anyway.
        top_source = sent_disambig[word_ndx].analyses[0].analysis['source']
        if top_source in IGNORE_SOURCE:
            word_diac = word_analyses[0].diac
            pred['is_oov'] = False
            pred['ct_diac_noctx'] = word_diac
            pred['ct_diac_soloctx'] = word_diac
            pred['ct_diac_fullctx'] = word_diac
            pred['ctpp_diac_soloctx'] = word_diac
            pred['ctpp_diac_fullctx'] = word_diac
            pred['oracle_diac_soloctx'] = word_diac
            pred['oracle_diac_fullctx'] = word_diac
            yield pred
            continue

        # Check if word is out-of-vocabulary (no anlyses or all analyses are
        # backoffs)
        is_oov = word_is_oov(word_analyses)
        pred['is_oov'] = is_oov

        # Diacritize word using original CT ranking and no context fixes
        if args.ct_noctx:
            ct_diac_noctx = word_analyses[0].diac
            pred['ct_diac_noctx'] = ct_diac_noctx

        # Diacritize word using original CT ranking and solo context fixes
        if args.ct_soloctx:
            ct_diac_soloctx = fix_contextual_diacs([word_analyses[0].diac])[0]
            ct_diac_soloctx = remove_contextual_diac_flags(ct_diac_soloctx)
            pred['ct_diac_soloctx'] = ct_diac_soloctx

        # Diacritize word using original CT ranking and full context fixes
        if args.ct_fullctx:
            ct_ctx_sent_diacs = sent_diacs[:]
            ct_ctx_sent_diacs = fix_contextual_diacs(ct_ctx_sent_diacs)
            ct_diac_fullctx = ct_ctx_sent_diacs[word_ndx]
            ct_diac_fullctx = remove_contextual_diac_flags(ct_diac_fullctx)
            pred['ct_diac_fullctx'] = ct_diac_fullctx

        # Rerank analyses using the CT++ ranking algorithm
        if args.ctpp_soloctx or args.ctpp_fullctx:
            ctpp_reranked = ctpp_rerank(word, word_analyses)
            ctpp_diac_pre = ctpp_reranked[0].diac
            ctpp_diac_pre = fix_tanween_alef(ctpp_diac_pre)

        # Diacritize word using CT++ reranking and solo context fixes
        if args.ctpp_soloctx:
            ctpp_diac_soloctx = fix_contextual_diacs([ctpp_diac_pre])[0]
            ctpp_diac_soloctx = remove_contextual_diac_flags(ctpp_diac_soloctx)
            ctpp_diac_soloctx = fix_diac_order(ctpp_diac_soloctx)
            pred['ctpp_diac_soloctx'] = ctpp_diac_soloctx

        # Diacritize word using CT++ reranking and full context fixes
        if args.ctpp_fullctx:
            ctpp_sent_diacs = sent_diacs[:]
            ctpp_sent_diacs[word_ndx] = ctpp_diac_pre
            ctpp_sent_diacs = fix_contextual_diacs(ctpp_sent_diacs)
            ctpp_diac_fullctx = ctpp_sent_diacs[word_ndx]
            ctpp_diac_fullctx = remove_contextual_diac_flags(ctpp_diac_fullctx)
            ctpp_diac_fullctx = fix_diac_order(ctpp_diac_fullctx)
            pred['ctpp_diac_fullctx'] = ctpp_diac_fullctx

        # Generate oracle diacritization using no context fixes
        if args.oracle_noctx:
            oracle_reranked = oracle_rerank_noctx(gold_diac, word_analyses)
            oracle_diac_noctx = oracle_reranked[0].diac
            pred['oracle_diac_noctx'] = oracle_diac_noctx

        # Generate oracle diacritization using solo context fixes
        if args.oracle_soloctx:
            oracle_reranked = oracle_rerank_ctx(gold_diac,
                                                [word],
                                                0,
                                                word_analyses)
            oracle_diac_soloctx = oracle_reranked[0].diac
            oracle_diac_soloctx = fix_contextual_diacs([oracle_diac_soloctx])[0]
            oracle_diac_soloctx = remove_contextual_diac_flags(oracle_diac_soloctx)
            oracle_diac_soloctx = fix_diac_order(oracle_diac_soloctx)
            pred['oracle_diac_soloctx'] = oracle_diac_soloctx

        # Generate oracle diacritization using full context fixes
        if args.oracle_fullctx:
            oracle_sent_diacs = sent_diacs[:]
            oracle_reranked = oracle_rerank_ctx(gold_diac,
                                                oracle_sent_diacs,
                                                word_ndx,
                                                word_analyses)
            oracle_sent_diacs[word_ndx] = oracle_reranked[0].diac
            oracle_sent_diacs = fix_contextual_diacs(oracle_sent_diacs)
            oracle_diac_fullctx = oracle_sent_diacs[word_ndx]
            oracle_diac_fullctx = remove_contextual_diac_flags(oracle_diac_fullctx)
            oracle_diac_fullctx = fix_diac_order(oracle_diac_fullctx)
            pred['oracle_diac_fullctx'] = oracle_diac_fullctx

        yield pred


def determine_output_columns(args: ProcessedArgs) -> List[str]:
    """Generate a list of columns to be written based on the passed
    command-line arguments.
    """

    columns = [
        # 'context_after',  # Uncommented during debugging
        'word',
        # 'context_before',  # Uncommented during debugging
        'gold_diac',
        'gold_diac_alt',
        'is_oov',
    ]

    if args.ct_noctx:
        columns.append('ct_diac_noctx')
    if args.ct_soloctx:
        columns.append('ct_diac_soloctx')
    if args.ct_fullctx:
        columns.append('ct_diac_fullctx')
    if args.ctpp_soloctx:
        columns.append('ctpp_diac_soloctx')
    if args.ctpp_fullctx:
        columns.append('ctpp_diac_fullctx')
    if args.oracle_noctx:
        columns.append('oracle_diac_noctx')
    if args.oracle_soloctx:
        columns.append('oracle_diac_soloctx')
    if args.oracle_fullctx:
        columns.append('oracle_diac_fullctx')

    return columns


def write_predictions(path: Path,
                      columns: List[str],
                      predictions: Iterable[dict[str, Any]]):
    """Writes predictions to a TSV file at a given path.
    """

    with path.open('w', encoding='utf-8', newline='\n') as fp:
        writer = csv.DictWriter(fp,
                                dialect='excel-tab',
                                fieldnames=columns,
                                quotechar=None,
                                quoting=csv.QUOTE_NONE,
                                extrasaction='ignore',
                                lineterminator='\n')
        writer.writeheader()
        for pred in predictions:
            writer.writerow(pred)


def main():
    # Parse command-line arguments
    argparser = create_argparser()
    args = argparser.parse_args()
    args = process_args(args)

    # Disable unwanted warnings from transformers
    tflogging.set_verbosity_error()

    # Set up disambiguator to use custom DB
    disambig = Disambig.pretrained('msa',
                                   top=5000,
                                   pretrained_cache=False)
    s31_db = MorphologyDB(args.db_path, 'a')
    s31_an = Analyzer(s31_db, 'ADD_PROP', cache_size=100000)
    disambig._analyzer = s31_an

    # Generate desired predictions
    predictions = gen_predictions(args, disambig)

    # Write generated predictions to file
    output_columns = determine_output_columns(args)
    write_predictions(args.output_path, output_columns, predictions)


if __name__ == '__main__':
    main()
